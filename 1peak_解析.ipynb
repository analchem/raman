{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl.drawing.line import LineProperties\n",
    "from openpyxl.chart.shapes import GraphicalProperties\n",
    "from openpyxl.chart.text import RichText\n",
    "from openpyxl.drawing.text import Paragraph, ParagraphProperties, CharacterProperties, Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各フォルダの読み込み\n",
    "folder_list = glob.glob(r'.\\input\\spectra_data\\*')\n",
    "\n",
    "# データの区切りを指定（タブ：'\\t', コンマ：',', セミコロン：';'）\n",
    "sep = '[,;\\t]'\n",
    "\n",
    "# excelファイルの保存先のパス\n",
    "output_path = r'.\\output\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['CH3:COOH=1:0', 'CH3:COOH=3:1', 'CH3:COOH=1:1', 'CH3:COOH=1:3', 'CH3:COOH=0:1']\n",
    "# label_list = ['CH3:OH=1:0', 'CH3:OH=3:1', 'CH3:OH=1:1', 'CH3:OH=1:3', 'CH3:OH=0:1']\n",
    "# label_list = ['CH3:NH2=1:0', 'CH3:NH2=3:1', 'CH3:NH2=1:1', 'CH3:NH2=1:3', 'CH3:NH2=0:1']\n",
    "# label_list = ['CH3:COOH=0:1', 'CH3:COOH=1:3', 'CH3:COOH=1:1', 'CH3:COOH=3:1', 'CH3:COOH=1:0', 'CH3:NH2=3:1', 'CH3:NH2=1:1', 'CH3:NH2=1:3', 'CH3:NH2=0:1']\n",
    "\n",
    "# データフレームの読み込み\n",
    "dataframe_path = r'.\\input\\dataframe\\\\'\n",
    "# excelファイルの保存先のパス\n",
    "output_path = r'.\\output\\\\'\n",
    "\n",
    "dataframe_title = 'P50_CH3_COOH_df'\n",
    "\n",
    "data_df = pd.read_excel(dataframe_path + dataframe_title + '.xlsx')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量とラベルの分離\n",
    "data_label = data_df['label']\n",
    "data_df = data_df.drop('label', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クロスバリデーションでの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel:rbf(ガウス関数) その他：linear(線形回帰)、poly(多項式展開)、sigmoidなどがある\n",
    "def linear_svc(C, data_df, label):\n",
    "    # SVM処理\n",
    "    # 特徴量とラベルの分割\n",
    "    X = data_df\n",
    "    X.columns = [str(i) for i in data_df.columns]\n",
    "    y = label\n",
    "    oof = np.zeros(len(y))\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        train_x, val_x = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        train_y, val_y = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        svm_model = LinearSVC(C=C)\n",
    "        svm_model.fit(train_x, train_y)\n",
    "        y_pred = svm_model.predict(val_x)\n",
    "        oof[val_idx] = y_pred\n",
    "\n",
    "    cm = confusion_matrix(y, oof)\n",
    "    # 正解率\n",
    "    Accuracy = accuracy_score(y, oof)\n",
    "\n",
    "    return cm, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cの決定\n",
    "temp_accuracy_dict = {}\n",
    "\n",
    "for i in range(-5, 6, 1):\n",
    "    _, accuracy_svm = linear_svc(10**i, data_df, data_label)\n",
    "    temp_accuracy_dict[i] = accuracy_svm\n",
    "\n",
    "temp_accuracy_list = temp_accuracy_dict.items()\n",
    "x, y = zip(*temp_accuracy_list)\n",
    "\n",
    "plt.plot(x, y, marker='o', markersize=5)\n",
    "plt.xlabel('C(10**i)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_linear_svc, accuracy_linear_svc = linear_svc(1, data_df, data_label)\n",
    "print('Accuracy:', accuracy_linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(cm_linear_svc, annot=True, cmap='Blues', linecolor='black', linewidths=1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データでの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_svc(C, data_df, label):\n",
    "    # SVM処理\n",
    "    # 特徴量とラベルの分割\n",
    "    X = data_df\n",
    "    X.columns = [str(i) for i in data_df.columns]\n",
    "    y = label\n",
    "\n",
    "    svm_model = LinearSVC(C=C)\n",
    "    svm_model.fit(X, y)\n",
    "    y_pred = svm_model.predict(X)\n",
    "\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    # 正解率\n",
    "    Accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    return cm, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cm_linear_svc, train_accuracy_linear_svc = train_linear_svc(100, data_df, data_label)\n",
    "print('Accuracy:', train_accuracy_linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(train_cm_linear_svc, annot=True, cmap='Blues', linecolor='black', linewidths=1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クロスバリデーションでの予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(data_df, label):\n",
    "    # SVM処理\n",
    "    # 特徴量とラベルの分割\n",
    "    X = data_df\n",
    "    X.columns = [str(i) for i in data_df.columns]\n",
    "    y = label\n",
    "    oof = np.zeros(len(y))\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        train_x, val_x = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        train_y, val_y = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        per_model = Perceptron()\n",
    "        per_model.fit(train_x, train_y)\n",
    "        y_pred = per_model.predict(val_x)\n",
    "        oof[val_idx] = y_pred\n",
    "\n",
    "    cm = confusion_matrix(y, oof)\n",
    "    # 正解率\n",
    "    Accuracy = accuracy_score(y, oof)\n",
    "\n",
    "    return cm, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_per, accuracy_per = perceptron(data_df, data_label)\n",
    "print('Accuracy:', accuracy_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(cm_per, annot=True, cmap='Blues', linecolor='black', linewidths=1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(data_df, label):\n",
    "    # 特徴量とラベルの分割\n",
    "    X = data_df\n",
    "    X.columns = [str(i) for i in data_df.columns]\n",
    "    y = label\n",
    "    oof = np.zeros(len(y))\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        train_x, val_x = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        train_y, val_y = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        log_model = LogisticRegression()\n",
    "        log_model.fit(train_x, train_y)\n",
    "        y_pred = log_model.predict(val_x)\n",
    "        oof[val_idx] = y_pred\n",
    "\n",
    "    cm = confusion_matrix(y, oof)\n",
    "    # 正解率\n",
    "    Accuracy = accuracy_score(y, oof)\n",
    "\n",
    "    return cm, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_log, accuracy_log = perceptron(data_df, data_label)\n",
    "print('Accuracy:', accuracy_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(cm_log, annot=True, cmap='Blues', linecolor='black', linewidths=1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-19ec329d61c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtest_dataframe_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'CH3_COOH_OH_NH2_standard_df'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdataframe_title\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtest_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtest_dataframe_title\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# 特徴量とラベルの分離\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\r-swx\\Anaconda3\\envs\\For_study\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    189\u001b[0m                     \u001b[1;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;31m# e.g.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unsupported pickle protocol: 5"
     ]
    }
   ],
   "source": [
    "# label_list = ['CH3:COOH=1:0', 'CH3:COOH=3:1', 'CH3:COOH=1:1', 'CH3:COOH=1:3', 'CH3:COOH=0:1']\n",
    "# label_list = ['CH3:OH=1:0', 'CH3:OH=3:1', 'CH3:OH=1:1', 'CH3:OH=1:3', 'CH3:OH=0:1']\n",
    "# label_list = ['CH3:NH2=1:0', 'CH3:NH2=3:1', 'CH3:NH2=1:1', 'CH3:NH2=1:3', 'CH3:NH2=0:1']\n",
    "label_list = ['CH3:COOH=1:0', 'CH3:COOH=3:1', 'CH3:COOH=1:1', 'CH3:COOH=1:3', 'CH3:COOH=0:1',\n",
    "              'CH3:OH=3:1', 'CH3:OH=1:1', 'CH3:OH=1:3', 'CH3:OH=0:1',\n",
    "              'CH3:NH2=3:1', 'CH3:NH2=1:1', 'CH3:NH2=1:3', 'CH3:NH2=0:1']\n",
    "\n",
    "# データフレームの読み込み\n",
    "dataframe_path = r'.\\input\\dataframe\\\\'\n",
    "# excelファイルの保存先のパス\n",
    "output_path = r'.\\output\\\\'\n",
    "\n",
    "dataframe_title = 'CH3_COOH_OH_standard_df'\n",
    "test_dataframe_title = 'CH3_COOH_OH_NH2_standard_df'\n",
    "data_df = pd.read_pickle(dataframe_path + dataframe_title + '.pkl')\n",
    "test_data_df = pd.read_pickle(dataframe_path + test_dataframe_title + '.pkl')\n",
    "\n",
    "# 特徴量とラベルの分離\n",
    "data_label = data_df['label']\n",
    "test_data_label = test_data_df['label']\n",
    "data_df = data_df.drop('label', axis=1)\n",
    "test_data_df = test_data_df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_2D_plot(df, df_label, test_df):\n",
    "    lda = LDA(n_components=2)\n",
    "    X_r2 = lda.fit(df, df_label).transform(test_df)\n",
    "\n",
    "    color_list = ['red', 'orange', 'green', 'blue', 'purple', 'cyan', 'gold', 'grey', 'black', 'lime', 'navy', 'pink', 'brown']\n",
    "\n",
    "    # Percentage of variance explained for each components\n",
    "    print('explained variance ratio (first two components): %s' % str(lda.explained_variance_ratio_))\n",
    "\n",
    "    for i in range(np.unique(test_data_label).size):\n",
    "        plt.scatter(X_r2[test_data_label == i, 0], X_r2[test_data_label == i, 1],\n",
    "        c=color_list[i], label=label_list[i])\n",
    "\n",
    "    # ldaの結果をデータフレーム化\n",
    "    lda_result_df = pd.DataFrame(X_r2)\n",
    "    lda_result_df.columns = ['LDA1', 'LDA2']\n",
    "    lda_result_df['label'] = data_label.values\n",
    "\n",
    "    # 重みベクトルの取得\n",
    "    lda_weight_vec_df = pd.DataFrame(lda.coef_, columns=data_df.columns, index=label_list)\n",
    "\n",
    "    plt.xlabel('LDA1')\n",
    "    plt.ylabel('LDA2')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    return lda_result_df, lda_weight_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_lda_result_df, scaled_lda_weight_vec_df = lda_2D_plot(data_df, data_label, test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "For_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
